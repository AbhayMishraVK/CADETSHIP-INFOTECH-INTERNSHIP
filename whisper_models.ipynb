{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbhayMishraVK/CADETSHIP-INFOTECH-INTERNSHIP/blob/main/whisper_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GCzRxAb0HPe",
        "outputId": "b2a7bdda-a9a3-43ea-972b-0cfd44949250"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install pydub\n",
        "! pip install transformers\n",
        "! pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BssGMPLl0qrb",
        "outputId": "5933d007-1fe7-47ad-e68c-59101ead4658"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.25.0\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljVdNVX94Z7O"
      },
      "source": [
        "Small Whisper Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 889
        },
        "id": "tv5PynvkzVOO",
        "outputId": "1691011d-1a01-41d8-e205-d00c22b3e529"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===================================\n",
            "Processing batch size: 1\n",
            "Result :  [{'text': ' Today we will tell you story. The topic is the crow and the fox. One day the crow was eating a piece of cheese. A cunning fox came there. He thought of asking the crow to sing a song. The foolish crow opened its mouth to sing. The cheese fell down. The cunning fox took the cheese and ran away. Moron, think before you act. Story from Panjatandra Tales. Thank you.'}]\n",
            "Total Inference Time for the batch: 23.040893077850342\n",
            "===================================\n",
            "Result :  [{'text': ' Artificial Intelligence has stood up to the front line of a real-world problem solving and business transformation. While intelligent document processing become a vital component in the global effort to drive intelligent automation into cooperative worldwide. IDP solution reads the unstructured raw data in complicated document using various AI related technologies. Including RPA boards, Optical Character Recognition, Natural Language Processing, Computer Vision and Machine Learning. IDP then gathers the crucial data and transform into the structure, patent and usable formats for is on shell process. Including Government, insurance, order invoicing and loan processing forms. Finally, IDP gathered the required data and forwarded it to appropriate departments or places first year along the line into the process.'}]\n",
            "Total Inference Time for the batch: 33.53029155731201\n",
            "===================================\n",
            "Result :  [{'text': ' Hello, I am Aghai and I am a software engineer intern. My current focus is on optimizing customer service. Of course, what do you share will depend on the situation and on the audience. If you are not sure what to share, your name and job title is a great place to start. If there is an option to elaborate, you can also share other details such as current projects, your expertise on your graphical location. The second part of the introduction is past tense. This is where all you can add or three points that will provide with relevant details about your background. It is also your option to establish a gravity bill. Consider your education and other credentials, past projects, employers and accomplishments. My background is in computer science. Before joining this team, I worked with Bigdata to identify insights for our client in the health care industry.'}]\n",
            "Total Inference Time for the batch: 30.627211093902588\n",
            "===================================\n",
            "Result :  [{'text': \" A one-minute story. Once there was a small village where the people were very poor. One day a king came to the village and offered to give each person a gold coin. Everyone was overjoyed and grateful except for one old woman who refused to take the coin. When asked why, she replied, I don't need a gold coin. I have something much more valuable. A Peaceful Heart Moral of the story is, a peaceful heart is more valuable than gold. Thanks for watching. Like, share, subscribe.\"}]\n",
            "Total Inference Time for the batch: 27.13752555847168\n",
            "===================================\n",
            "Result :  [{'text': \" The two silly goats, short moral story. Once upon a time, there were two silly goats. They wanted to cross a narrow bridge. One silly goat was on one side, the other silly goat was on the other side. They couldn't pass each other. Now both of them wanted to be first to cross. They began to fight. As they were fighting, both fell into the water and drowned. Moral of the story. Foolishness is always punished.\"}]\n",
            "Total Inference Time for the batch: 33.18052649497986\n",
            "===================================\n",
            "Result :  [{'text': \" A very short story with a very short moral. Once there was a girl with bright blue eyes who did only things that made her happy. The only time she wasn't happy was when she forgot that she only did things that made her happy. The end.\"}]\n",
            "Total Inference Time for the batch: 19.185746431350708\n",
            "===================================\n",
            "Result :  [{'text': ' My name is Abhay Mishra. I am currently pursuing computer science engineering from Jameli Devi Group of Institution. Also I am working as an intern in a soft-dude company under Mradul Kanuvo sir. Currently I am working in a project related to the speech to text. Currently I am using the whisper to convert the speech to text.'}]\n",
            "Total Inference Time for the batch: 22.609355449676514\n",
            "===================================\n",
            "Result :  [{'text': \" A very short moral story. with disappointment. Then the girl handed one to her mother and said, Here, this is the sweeter one. Moral, don't judge too early.\"}]\n",
            "Total Inference Time for the batch: 16.855469703674316\n",
            "===================================\n",
            "Result :  [{'text': ' Hello everyone, I am ready with one more short story for you all. Squirrel was very supportive and always won the race. The puppy used to feel bad and thought that of no use. One day it was raining heavily and the squirrel fell in a problem. He started jumping on the water puddle and suddenly fell down. He called his friendppy for help. The puppy came running to help his friend. The squirrel climbed on its back and reached the safe place. He thanked his friend for saving his life. Everyone is unique in their own way, just have confidence in you. Thank you.'}]\n",
            "Total Inference Time for the batch: 36.054413080215454\n",
            "===================================\n",
            "\n",
            "\n",
            "Processing batch size: 8\n",
            "Result :  [{'text': ' Today we will tell you story. The topic is the crow and the fox. One day the crow was eating a piece of cheese. A cunning fox came there. He thought of asking the crow to sing a song. The foolish crow opened its mouth to sing. The cheese fell down. The cunning fox took the cheese and ran away. Moron, think before you act. Story from Panjatandra Tales. Thank you.'}, {'text': ' Artificial Intelligence has stood up to the front line of a real-world problem solving and business transformation. While intelligent document processing become a vital component in the global effort to drive intelligent automation into cooperative worldwide. IDP solution reads the unstructured raw data in complicated document using various AI related technologies. Including RPA boards, Optical Character Recognition, Natural Language Processing, Computer Vision and Machine Learning. IDP then gathers the crucial data and transform into the structure, patent and usable formats for is on shell process. Including Government, insurance, order invoicing and loan processing forms. Finally, IDP gathered the required data and forwarded it to appropriate departments or places first year along the line into the process.'}, {'text': ' Hello, I am Aghai and I am a software engineer intern. My current focus is on optimizing customer service. Of course, what do you share will depend on the situation and on the audience. If you are not sure what to share, your name and job title is a great place to start. If there is an option to elaborate, you can also share other details such as current projects, your expertise on your graphical location. The second part of the introduction is past tense. This is where all you can add or three points that will provide with relevant details about your background. It is also your option to establish a gravity bill. Consider your education and other credentials, past projects, employers and accomplishments. My background is in computer science. Before joining this team, I worked with Bigdata to identify insights for our client in the health care industry.'}, {'text': \" A one-minute story. Once there was a small village where the people were very poor. One day a king came to the village and offered to give each person a gold coin. Everyone was overjoyed and grateful except for one old woman who refused to take the coin. When asked why, she replied, I don't need a gold coin. I have something much more valuable. A Peaceful Heart Moral of the story is, a peaceful heart is more valuable than gold. Thanks for watching. Like, share, subscribe.\"}, {'text': \" The two silly goats, short moral story. Once upon a time, there were two silly goats. They wanted to cross a narrow bridge. One silly goat was on one side, the other silly goat was on the other side. They couldn't pass each other. Now both of them wanted to be first to cross. They began to fight. As they were fighting, both fell into the water and drowned. Moral of the story. Foolishness is always punished.\"}, {'text': \" A very short story with a very short moral. Once there was a girl with bright blue eyes who did only things that made her happy. The only time she wasn't happy was when she forgot that she only did things that made her happy. The end.\"}, {'text': ' My name is Abhay Mishra. I am currently pursuing computer science engineering from Jameli Devi Group of Institution. Also I am working as an intern in a soft-dude company under Mradul Kanuvo sir. Currently I am working in a project related to the speech to text. Currently I am using the whisper to convert the speech to text.'}, {'text': \" A very short moral story. with disappointment. Then the girl handed one to her mother and said, Here, this is the sweeter one. Moral, don't judge too early.\"}]\n",
            "Total Inference Time for the batch: 194.95356678962708\n",
            "===================================\n",
            "Result :  [{'text': ' Hello everyone, I am ready with one more short story for you all. Squirrel was very supportive and always won the race. The puppy used to feel bad and thought that of no use. One day it was raining heavily and the squirrel fell in a problem. He started jumping on the water puddle and suddenly fell down. He called his friendppy for help. The puppy came running to help his friend. The squirrel climbed on its back and reached the safe place. He thanked his friend for saving his life. Everyone is unique in their own way, just have confidence in you. Thank you.'}]\n",
            "Total Inference Time for the batch: 37.7269868850708\n",
            "===================================\n",
            "\n",
            "\n",
            "Processing batch size: 9\n",
            "Result :  [{'text': ' Today we will tell you story. The topic is the crow and the fox. One day the crow was eating a piece of cheese. A cunning fox came there. He thought of asking the crow to sing a song. The foolish crow opened its mouth to sing. The cheese fell down. The cunning fox took the cheese and ran away. Moron, think before you act. Story from Panjatandra Tales. Thank you.'}, {'text': ' Artificial Intelligence has stood up to the front line of a real-world problem solving and business transformation. While intelligent document processing become a vital component in the global effort to drive intelligent automation into cooperative worldwide. IDP solution reads the unstructured raw data in complicated document using various AI related technologies. Including RPA boards, Optical Character Recognition, Natural Language Processing, Computer Vision and Machine Learning. IDP then gathers the crucial data and transform into the structure, patent and usable formats for is on shell process. Including Government, insurance, order invoicing and loan processing forms. Finally, IDP gathered the required data and forwarded it to appropriate departments or places first year along the line into the process.'}, {'text': ' Hello, I am Aghai and I am a software engineer intern. My current focus is on optimizing customer service. Of course, what do you share will depend on the situation and on the audience. If you are not sure what to share, your name and job title is a great place to start. If there is an option to elaborate, you can also share other details such as current projects, your expertise on your graphical location. The second part of the introduction is past tense. This is where all you can add or three points that will provide with relevant details about your background. It is also your option to establish a gravity bill. Consider your education and other credentials, past projects, employers and accomplishments. My background is in computer science. Before joining this team, I worked with Bigdata to identify insights for our client in the health care industry.'}, {'text': \" A one-minute story. Once there was a small village where the people were very poor. One day a king came to the village and offered to give each person a gold coin. Everyone was overjoyed and grateful except for one old woman who refused to take the coin. When asked why, she replied, I don't need a gold coin. I have something much more valuable. A Peaceful Heart Moral of the story is, a peaceful heart is more valuable than gold. Thanks for watching. Like, share, subscribe.\"}, {'text': \" The two silly goats, short moral story. Once upon a time, there were two silly goats. They wanted to cross a narrow bridge. One silly goat was on one side, the other silly goat was on the other side. They couldn't pass each other. Now both of them wanted to be first to cross. They began to fight. As they were fighting, both fell into the water and drowned. Moral of the story. Foolishness is always punished.\"}, {'text': \" A very short story with a very short moral. Once there was a girl with bright blue eyes who did only things that made her happy. The only time she wasn't happy was when she forgot that she only did things that made her happy. The end.\"}, {'text': ' My name is Abhay Mishra. I am currently pursuing computer science engineering from Jameli Devi Group of Institution. Also I am working as an intern in a soft-dude company under Mradul Kanuvo sir. Currently I am working in a project related to the speech to text. Currently I am using the whisper to convert the speech to text.'}, {'text': \" A very short moral story. with disappointment. Then the girl handed one to her mother and said, Here, this is the sweeter one. Moral, don't judge too early.\"}, {'text': ' Hello everyone, I am ready with one more short story for you all. Squirrel was very supportive and always won the race. The puppy used to feel bad and thought that of no use. One day it was raining heavily and the squirrel fell in a problem. He started jumping on the water puddle and suddenly fell down. He called his friendppy for help. The puppy came running to help his friend. The squirrel climbed on its back and reached the safe place. He thanked his friend for saving his life. Everyone is unique in their own way, just have confidence in you. Thank you.'}]\n",
            "Total Inference Time for the batch: 233.48734092712402\n",
            "===================================\n",
            "\n",
            "\n",
            "Logs saved to inference_logs_SmallBatch_16_batch.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nDocument :\\n\\n(1) It is fast then others but accuracy low.\\n(2) Distil-Whisper is currently only available for English speech recognition.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
        "from time import time\n",
        "import csv\n",
        "from pydub import AudioSegment\n",
        "\n",
        "\n",
        "# Define the device and supported torch data types\n",
        "device = \"cpu\"\n",
        "\n",
        "# Function to get audio duration in minutes\n",
        "def audio_duration_in_minutes(file_path):\n",
        "    audio = AudioSegment.from_file(file_path)\n",
        "    return len(audio) / 60000.0\n",
        "\n",
        "# Specify the local path to the pre-trained model directory\n",
        "model_id = \"openai/whisper-small\"\n",
        "\n",
        "# Load the pre-trained model from the local directory\n",
        "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
        "    model_id, torch_dtype=torch.float32\n",
        ")\n",
        "\n",
        "# Move the model to the selected device\n",
        "model.to(device)\n",
        "\n",
        "# Load the processor from the specific snapshot directory within the model directory\n",
        "processor = AutoProcessor.from_pretrained(\n",
        "   \"openai/whisper-small\")\n",
        "\n",
        "# Parameters\n",
        "dtype_precision_values = [torch.float32]\n",
        "batch_size_values = [1, 8, 9]\n",
        "\n",
        "# INPUT FILES\n",
        "audio_files = [\n",
        "    \"testing (1).mp3\",\n",
        "    \"testing (2).mp3\",\n",
        "    \"testing (3).mp3\",\n",
        "    \"testing (4).mp3\",\n",
        "    \"testing (5).mp3\",\n",
        "    \"testing (6).mp3\",\n",
        "    \"testing (7).mp3\",\n",
        "    \"testing (8).mp3\",\n",
        "    \"testing (9).mp3\",\n",
        "]\n",
        "\n",
        "# Initialize a CSV file for recording experiment logs\n",
        "csv_file_name = \"inference_logs_SmallBatch_16_batch.csv\"\n",
        "with open(csv_file_name, 'w', newline='') as csv_file:\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerow(['Dtype Precision', 'Batch Size', 'Inference Time', 'File(s) Processed'])\n",
        "\n",
        "    for dtype_precision in dtype_precision_values:\n",
        "        torch_dtype = dtype_precision\n",
        "        print(\"===================================\")\n",
        "        for batch_size in batch_size_values:\n",
        "            # Print the current batch size being processed\n",
        "            print(f\"Processing batch size: {batch_size}\")\n",
        "\n",
        "            # Initialize the pipeline outside the loop to avoid repeated initialization\n",
        "            pipe = pipeline(\n",
        "                \"automatic-speech-recognition\",\n",
        "                model=model,\n",
        "                device=device,\n",
        "                chunk_length_s=30,\n",
        "                tokenizer=processor.tokenizer,\n",
        "                feature_extractor=processor.feature_extractor,\n",
        "                torch_dtype=torch_dtype,\n",
        "                batch_size = 8\n",
        "            )\n",
        "\n",
        "            # Run inference in batches\n",
        "            for i in range(0, len(audio_files), batch_size):\n",
        "                batch_files = audio_files[i:i + batch_size]\n",
        "                filenames = list(batch_files)  # Capture filenames\n",
        "\n",
        "                inference_start_time = time()\n",
        "                results = pipe(batch_files)\n",
        "                inference_end_time = time()\n",
        "\n",
        "                total_inference_time = inference_end_time - inference_start_time\n",
        "                avg_inference_time_per_file = total_inference_time / len(batch_files) if batch_files else 0\n",
        "\n",
        "                # Append audio duration for single-file batches\n",
        "                if len(filenames) == 1:\n",
        "                    filenames[0] += f\" ({audio_duration_in_minutes(filenames[0]):.2f} mins)\"\n",
        "\n",
        "                # Record the experiment logs in the CSV file\n",
        "                csv_writer.writerow([torch_dtype, batch_size, avg_inference_time_per_file, \", \".join(filenames)])\n",
        "\n",
        "                print(\"Result : \", results)\n",
        "                print(f\"Total Inference Time for the batch: {total_inference_time}\")\n",
        "                print(\"===================================\")\n",
        "            print(\"\\n\")\n",
        "\n",
        "    print(f\"Logs saved to {csv_file_name}\")\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Document :\n",
        "\n",
        "(1) It is fast then others but accuracy low.\n",
        "(2) Distil-Whisper is currently only available for English speech recognition.\n",
        "\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFfP90-U6HXN"
      },
      "source": [
        "Distil Small"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 906
        },
        "id": "Du3_S_8d6ElV",
        "outputId": "e8050f63-ffa4-42af-cd2a-16f7746f04e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===================================\n",
            "Processing batch size: 1\n",
            "Result :  [{'text': ' The next day the crow was eating a piece of cheese. Today will tell you a story. The topic is the crow and the fox. One day the crow was eating a piece of cheese. A cunning fox came there. He thought of asking the crow to sing a song. The foolish crow opened its mouth to sing. The cheese fell down. The cunning fox took the cheese under away. More thing before you act. Story from Pangyadandratil. Thank you.'}]\n",
            "Total Inference Time for the batch: 2.591956615447998\n",
            "===================================\n",
            "Result :  [{'text': ' Artificial intelligence has stayed up to the front line of a real world problem solving and business transformation. While intelligent document processing become a vital component in the global effort to drive intelligent automation into cooperative worldwide. IDP solution reads the undestructured raw data in complicated document using various AI related technologies including RPA about optical character recognition, natural language processing, computer vision and machine learning. IDP then gathers the crucial data and transform into the structure patent and usable formats for is oncial process, including government, banking, insurance, order invoicing and long processing forms. Finally, IDB gathered the required data and forwarded to a appropriate department or places further along the line into the process.'}]\n",
            "Total Inference Time for the batch: 2.789340019226074\n",
            "===================================\n",
            "Result :  [{'text': ' Hello, I am Agai and I am a software engineer in turn. My current focus is on optimizing customer service. Of course, what do you say here will depend on the situation and on the audience? If you are not sure what to say here, your norm and job title is a great place to start. If there is an opportunity to elaborate, you can also share other details such as current project, your expertise on your graphical location. The second part of the introduction is past and this is where all you can add or three points that will provide with relevant details about your background. It is also your opportunity to establish creditivity bill. Consider your education and other credentials, past project employers and accomplishment. My background is in computer science. Before joining this team, I worked with Big Data to identify insights for our client in the health care industry.'}]\n",
            "Total Inference Time for the batch: 2.935457229614258\n",
            "===================================\n",
            "Result :  [{'text': \" A one minute story. Once there was a small village where the people were very poor. One day a king came to the village and offered to give each person a gold coin. Everyone was overjoyed and grateful except for one old woman who refused to tag the coin. When asked why she replied I don't need a gold coin I have something much more valuable a peaceful hurt. Moral of the story is a peaceful hurt is more valuable than gold. Thanks for watching. Like share subscribe.\"}]\n",
            "Total Inference Time for the batch: 1.3658452033996582\n",
            "===================================\n",
            "Result :  [{'text': \" The two silly goats shot Marl's story. Once upon a time, there were two silly goats. They wanted to cross a narrow bridge. One silly goat was on one side, the other silly goat was on the other side. They couldn't pass each other. Now, both of them wanted to be first to cross. They began to fight. As they were fighting, both fell into the water and drowned. Moral of the story. Foolishness is always punished. Thanks for watching. Make sure to like and subscribe.\"}]\n",
            "Total Inference Time for the batch: 1.5189695358276367\n",
            "===================================\n",
            "Result :  [{'text': \" A very short story with a very short moral. Once there was a girl with bright blue eyes who did only things that made her happy. The only time she wasn't happy was when she forgot that she only did things that made her happy. The end.\"}]\n",
            "Total Inference Time for the batch: 0.7850346565246582\n",
            "===================================\n",
            "Result :  [{'text': ' My name is Ava Hemisphere. I am currently pursuing computer science engineering from Chemelidevi Group of Institution. Also, I am working as an intern in a software company under Madhul Khanovasar. Currently, I am working in a project related to the speech-to-text. Currently, I am using the whisper to convert the speech to text. Currently I am using the whisper to convert the speech to text.'}]\n",
            "Total Inference Time for the batch: 0.8761494159698486\n",
            "===================================\n",
            "Result :  [{'text': \" A very short moral story. A little girl was holding two apples. Her mother asked for one. The girl quickly bit one apple and then another one. Her mother held back with disappointment. Then the girl handed one to her mother and said, Here, this is the sweeter one. Moral, don't judge too early.\"}]\n",
            "Total Inference Time for the batch: 0.8513860702514648\n",
            "===================================\n",
            "Result :  [{'text': \" Hello everyone! I'm ready with one more short story for you all! The story is The Truthful Friend. Here we go! Once there were two friends, a squirrel and a puppy. They used to live and play together. The squirrel was very supportive and always wondrous. The puppy used to feel bad and thought that of no use. One day, it was raining heavily and the squirrel fell in a problem. He started jumping on the water puddle and suddenly fell down. He called his friend puppy for help. The puppy came running to help his friend. The squirrel climbed on its back and reached the safe place. He thanked his friend for saving his life. Morrel of the story. Everyone is unique in their own way. Just have confidence in you. Thank you.\"}]\n",
            "Total Inference Time for the batch: 2.3445301055908203\n",
            "===================================\n",
            "\n",
            "\n",
            "Processing batch size: 8\n",
            "Result :  [{'text': ' The next day the crow was eating a piece of cheese. Today will tell you a story. The topic is the crow and the fox. One day the crow was eating a piece of cheese. A cunning fox came there. He thought of asking the crow to sing a song. The foolish crow opened its mouth to sing. The cheese fell down. The cunning fox took the cheese under away. More thing before you act. Story from Pangyadandratil. Thank you.'}, {'text': ' Artificial intelligence has stayed up to the front line of a real world problem solving and business transformation. While intelligent document processing become a vital component in the global effort to drive intelligent automation into cooperative worldwide. IDP solution reads the undestructured raw data in complicated document using various AI related technologies including RPA about optical character recognition, natural language processing, computer vision and machine learning. IDP then gathers the crucial data and transform into the structure patent and usable formats for is oncial process, including government, banking, insurance, order invoicing and long processing forms. Finally, IDB gathered the required data and forwarded to a appropriate department or places further along the line into the process.'}, {'text': ' Hello, I am Agai and I am a software engineer in turn. My current focus is on optimizing customer service. Of course, what do you say here will depend on the situation and on the audience? If you are not sure what to say here, your norm and job title is a great place to start. If there is an opportunity to elaborate, you can also share other details such as current project, your expertise on your graphical location. The second part of the introduction is past and this is where all you can add or three points that will provide with relevant details about your background. It is also your opportunity to establish creditivity bill. Consider your education and other credentials, past project employers and accomplishment. My background is in computer science. Before joining this team, I worked with Big Data to identify insights for our client in the health care industry.'}, {'text': \" A one minute story. Once there was a small village where the people were very poor. One day a king came to the village and offered to give each person a gold coin. Everyone was overjoyed and grateful except for one old woman who refused to tag the coin. When asked why she replied I don't need a gold coin I have something much more valuable a peaceful hurt. Moral of the story is a peaceful hurt is more valuable than gold. Thanks for watching. Like share subscribe.\"}, {'text': \" The two silly goats shot Marl's story. Once upon a time, there were two silly goats. They wanted to cross a narrow bridge. One silly goat was on one side, the other silly goat was on the other side. They couldn't pass each other. Now, both of them wanted to be first to cross. They began to fight. As they were fighting, both fell into the water and drowned. Moral of the story. Foolishness is always punished. Thanks for watching. Make sure to like and subscribe.\"}, {'text': \" A very short story with a very short moral. Once there was a girl with bright blue eyes who did only things that made her happy. The only time she wasn't happy was when she forgot that she only did things that made her happy. The end.\"}, {'text': ' My name is Ava Hemisphere. I am currently pursuing computer science engineering from Chemelidevi Group of Institution. Also, I am working as an intern in a software company under Madhul Khanovasar. Currently, I am working in a project related to the speech-to-text. Currently, I am using the whisper to convert the speech to text. Currently I am using the whisper to convert the speech to text.'}, {'text': \" A very short moral story. A little girl was holding two apples. Her mother asked for one. The girl quickly bit one apple and then another one. Her mother held back with disappointment. Then the girl handed one to her mother and said, Here, this is the sweeter one. Moral, don't judge too early.\"}]\n",
            "Total Inference Time for the batch: 9.70171332359314\n",
            "===================================\n",
            "Result :  [{'text': \" Hello everyone! I'm ready with one more short story for you all! The story is The Truthful Friend. Here we go! Once there were two friends, a squirrel and a puppy. They used to live and play together. The squirrel was very supportive and always wondrous. The puppy used to feel bad and thought that of no use. One day, it was raining heavily and the squirrel fell in a problem. He started jumping on the water puddle and suddenly fell down. He called his friend puppy for help. The puppy came running to help his friend. The squirrel climbed on its back and reached the safe place. He thanked his friend for saving his life. Morrel of the story. Everyone is unique in their own way. Just have confidence in you. Thank you.\"}]\n",
            "Total Inference Time for the batch: 2.2206690311431885\n",
            "===================================\n",
            "\n",
            "\n",
            "Processing batch size: 9\n",
            "Result :  [{'text': ' The next day the crow was eating a piece of cheese. Today will tell you a story. The topic is the crow and the fox. One day the crow was eating a piece of cheese. A cunning fox came there. He thought of asking the crow to sing a song. The foolish crow opened its mouth to sing. The cheese fell down. The cunning fox took the cheese under away. More thing before you act. Story from Pangyadandratil. Thank you.'}, {'text': ' Artificial intelligence has stayed up to the front line of a real world problem solving and business transformation. While intelligent document processing become a vital component in the global effort to drive intelligent automation into cooperative worldwide. IDP solution reads the undestructured raw data in complicated document using various AI related technologies including RPA about optical character recognition, natural language processing, computer vision and machine learning. IDP then gathers the crucial data and transform into the structure patent and usable formats for is oncial process, including government, banking, insurance, order invoicing and long processing forms. Finally, IDB gathered the required data and forwarded to a appropriate department or places further along the line into the process.'}, {'text': ' Hello, I am Agai and I am a software engineer in turn. My current focus is on optimizing customer service. Of course, what do you say here will depend on the situation and on the audience? If you are not sure what to say here, your norm and job title is a great place to start. If there is an opportunity to elaborate, you can also share other details such as current project, your expertise on your graphical location. The second part of the introduction is past and this is where all you can add or three points that will provide with relevant details about your background. It is also your opportunity to establish creditivity bill. Consider your education and other credentials, past project employers and accomplishment. My background is in computer science. Before joining this team, I worked with Big Data to identify insights for our client in the health care industry.'}, {'text': \" A one minute story. Once there was a small village where the people were very poor. One day a king came to the village and offered to give each person a gold coin. Everyone was overjoyed and grateful except for one old woman who refused to tag the coin. When asked why she replied I don't need a gold coin I have something much more valuable a peaceful hurt. Moral of the story is a peaceful hurt is more valuable than gold. Thanks for watching. Like share subscribe.\"}, {'text': \" The two silly goats shot Marl's story. Once upon a time, there were two silly goats. They wanted to cross a narrow bridge. One silly goat was on one side, the other silly goat was on the other side. They couldn't pass each other. Now, both of them wanted to be first to cross. They began to fight. As they were fighting, both fell into the water and drowned. Moral of the story. Foolishness is always punished. Thanks for watching. Make sure to like and subscribe.\"}, {'text': \" A very short story with a very short moral. Once there was a girl with bright blue eyes who did only things that made her happy. The only time she wasn't happy was when she forgot that she only did things that made her happy. The end.\"}, {'text': ' My name is Ava Hemisphere. I am currently pursuing computer science engineering from Chemelidevi Group of Institution. Also, I am working as an intern in a software company under Madhul Khanovasar. Currently, I am working in a project related to the speech-to-text. Currently, I am using the whisper to convert the speech to text. Currently I am using the whisper to convert the speech to text.'}, {'text': \" A very short moral story. A little girl was holding two apples. Her mother asked for one. The girl quickly bit one apple and then another one. Her mother held back with disappointment. Then the girl handed one to her mother and said, Here, this is the sweeter one. Moral, don't judge too early.\"}, {'text': \" Hello everyone! I'm ready with one more short story for you all! The story is The Truthful Friend. Here we go! Once there were two friends, a squirrel and a puppy. They used to live and play together. The squirrel was very supportive and always wondrous. The puppy used to feel bad and thought that of no use. One day, it was raining heavily and the squirrel fell in a problem. He started jumping on the water puddle and suddenly fell down. He called his friend puppy for help. The puppy came running to help his friend. The squirrel climbed on its back and reached the safe place. He thanked his friend for saving his life. Morrel of the story. Everyone is unique in their own way. Just have confidence in you. Thank you.\"}]\n",
            "Total Inference Time for the batch: 11.878546476364136\n",
            "===================================\n",
            "\n",
            "\n",
            "Logs saved to inference_logs_distilSmallBatch_16_gpu.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nDocument :\\n\\n(1) It is fast then others but accuracy low.\\n(2) Distil-Whisper is currently only available for English speech recognition.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
        "from time import time\n",
        "import csv\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Define the device and supported torch data types\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Function to get audio duration in minutes\n",
        "def audio_duration_in_minutes(file_path):\n",
        "    audio = AudioSegment.from_file(file_path)\n",
        "    return len(audio) / 60000.0\n",
        "\n",
        "# Specify the local path to the pre-trained model directory\n",
        "model_id = \"distil-whisper/distil-small.en\"\n",
        "\n",
        "\n",
        "# Load the pre-trained model from the local directory\n",
        "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
        "    model_id, torch_dtype=torch.float32\n",
        ")\n",
        "\n",
        "# Move the model to the selected device\n",
        "model.to(device)\n",
        "\n",
        "# Load the processor from the specific snapshot directory within the model directory\n",
        "processor = AutoProcessor.from_pretrained(\n",
        "    model_id\n",
        ")\n",
        "\n",
        "# Parameters\n",
        "dtype_precision_values = [torch.float16]\n",
        "batch_size_values = [1, 8, 9]\n",
        "\n",
        "# INPUT FILES\n",
        "# INPUT FILES\n",
        "audio_files = [\n",
        "    \"testing (1).mp3\",\n",
        "    \"testing (2).mp3\",\n",
        "    \"testing (3).mp3\",\n",
        "    \"testing (4).mp3\",\n",
        "    \"testing (5).mp3\",\n",
        "    \"testing (6).mp3\",\n",
        "    \"testing (7).mp3\",\n",
        "    \"testing (8).mp3\",\n",
        "    \"testing (9).mp3\",\n",
        "]\n",
        "\n",
        "# Initialize a CSV file for recording experiment logs\n",
        "csv_file_name = \"inference_logs_distilSmallBatch_16_gpu.csv\"\n",
        "with open(csv_file_name, 'w', newline='') as csv_file:\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerow(['Dtype Precision', 'Batch Size', 'Inference Time', 'File(s) Processed'])\n",
        "\n",
        "    for dtype_precision in dtype_precision_values:\n",
        "        torch_dtype = dtype_precision\n",
        "        print(\"===================================\")\n",
        "        for batch_size in batch_size_values:\n",
        "            # Print the current batch size being processed\n",
        "            print(f\"Processing batch size: {batch_size}\")\n",
        "\n",
        "            # Initialize the pipeline outside the loop to avoid repeated initialization\n",
        "            pipe = pipeline(\n",
        "                \"automatic-speech-recognition\",\n",
        "                model=model.half(),\n",
        "                device=device,\n",
        "                chunk_length_s=30,\n",
        "                tokenizer=processor.tokenizer,\n",
        "                feature_extractor=processor.feature_extractor,\n",
        "                torch_dtype=torch_dtype\n",
        "            )\n",
        "\n",
        "            # Run inference in batches\n",
        "            for i in range(0, len(audio_files), batch_size):\n",
        "                batch_files = audio_files[i:i + batch_size]\n",
        "                filenames = list(batch_files)  # Capture filenames\n",
        "\n",
        "                inference_start_time = time()\n",
        "                results = pipe(batch_files)\n",
        "                inference_end_time = time()\n",
        "\n",
        "                total_inference_time = inference_end_time - inference_start_time\n",
        "                avg_inference_time_per_file = total_inference_time / len(batch_files) if batch_files else 0\n",
        "\n",
        "                # Append audio duration for single-file batches\n",
        "                if len(filenames) == 1:\n",
        "                    filenames[0] += f\" ({audio_duration_in_minutes(filenames[0]):.2f} mins)\"\n",
        "\n",
        "                # Record the experiment logs in the CSV file\n",
        "                csv_writer.writerow([torch_dtype, batch_size, avg_inference_time_per_file, \", \".join(filenames)])\n",
        "\n",
        "                print(\"Result : \", results)\n",
        "                print(f\"Total Inference Time for the batch: {total_inference_time}\")\n",
        "                print(\"===================================\")\n",
        "            print(\"\\n\")\n",
        "\n",
        "    print(f\"Logs saved to {csv_file_name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6oQpIFdEPnr"
      },
      "source": [
        "Whisper Medium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SL4XBP8KES1f",
        "outputId": "fc7bc7e7-7a16-4ba8-e186-d2338a86d3f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===================================\n",
            "Processing batch size: 1\n",
            "Batch Files:  ['testing (1).mp3']\n",
            "Total Inference Time for the batch:  1.9090971946716309\n",
            "===================================\n",
            "Batch Files:  ['testing (2).mp3']\n",
            "Total Inference Time for the batch:  4.4130096435546875\n",
            "===================================\n",
            "Batch Files:  ['testing (3).mp3']\n",
            "Total Inference Time for the batch:  6.836504697799683\n",
            "===================================\n",
            "Batch Files:  ['testing (4).mp3']\n",
            "Total Inference Time for the batch:  3.924983024597168\n",
            "===================================\n",
            "Batch Files:  ['testing (5).mp3']\n",
            "Total Inference Time for the batch:  4.520305633544922\n",
            "===================================\n",
            "Batch Files:  ['testing (6).mp3']\n",
            "Total Inference Time for the batch:  2.4291632175445557\n",
            "===================================\n",
            "Batch Files:  ['testing (7).mp3']\n",
            "Total Inference Time for the batch:  2.7300164699554443\n",
            "===================================\n",
            "Batch Files:  ['testing (8).mp3']\n",
            "Total Inference Time for the batch:  1.4631083011627197\n",
            "===================================\n",
            "Batch Files:  ['testing (9).mp3']\n",
            "Total Inference Time for the batch:  6.214992523193359\n",
            "===================================\n",
            "\n",
            "\n",
            "Processing batch size: 8\n",
            "Batch Files:  ['testing (1).mp3', 'testing (2).mp3', 'testing (3).mp3', 'testing (4).mp3', 'testing (5).mp3', 'testing (6).mp3', 'testing (7).mp3', 'testing (8).mp3']\n",
            "Total Inference Time for the batch:  28.654138326644897\n",
            "===================================\n",
            "Batch Files:  ['testing (9).mp3']\n",
            "Total Inference Time for the batch:  5.000476360321045\n",
            "===================================\n",
            "\n",
            "\n",
            "Processing batch size: 9\n",
            "Batch Files:  ['testing (1).mp3', 'testing (2).mp3', 'testing (3).mp3', 'testing (4).mp3', 'testing (5).mp3', 'testing (6).mp3', 'testing (7).mp3', 'testing (8).mp3', 'testing (9).mp3']\n",
            "Total Inference Time for the batch:  33.58625650405884\n",
            "===================================\n",
            "\n",
            "\n",
            "Logs saved to inference_logs_mediumBatch_gpu.csv\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
        "from time import time\n",
        "import csv\n",
        "\n",
        "# Define the device and supported torch data types\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Function to get audio duration in minutes\n",
        "def audio_duration_in_minutes(file_path):\n",
        "    # Implement your logic to get audio duration using pydub or other libraries\n",
        "    pass\n",
        "\n",
        "# Specify the local path to the pre-trained model directory\n",
        "model_id = \"openai/whisper-medium\"\n",
        "\n",
        "# Load the pre-trained model from the local directory\n",
        "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
        "    model_id, torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "# Move the model to the selected device\n",
        "model.to(device)\n",
        "\n",
        "# Load the processor from the specific snapshot directory within the model directory\n",
        "processor = AutoProcessor.from_pretrained(\n",
        "    \"openai/whisper-medium\"\n",
        ")\n",
        "\n",
        "# Parameters\n",
        "dtype_precision_values = [torch.float16]\n",
        "batch_size_values = [1, 8, 9]\n",
        "\n",
        "# INPUT FILES\n",
        "audio_files = [\n",
        "    \"testing (1).mp3\",\n",
        "    \"testing (2).mp3\",\n",
        "    \"testing (3).mp3\",\n",
        "    \"testing (4).mp3\",\n",
        "    \"testing (5).mp3\",\n",
        "    \"testing (6).mp3\",\n",
        "    \"testing (7).mp3\",\n",
        "    \"testing (8).mp3\",\n",
        "    \"testing (9).mp3\",\n",
        "]\n",
        "\n",
        "# Initialize a CSV file for recording experiment logs\n",
        "csv_file_name = \"inference_logs_mediumBatch_gpu.csv\"\n",
        "with open(csv_file_name, 'w', newline='') as csv_file:\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerow(['Dtype Precision', 'Batch Size', 'Inference Time'])\n",
        "\n",
        "    for dtype_precision in dtype_precision_values:\n",
        "        torch_dtype = dtype_precision\n",
        "        print(\"===================================\")\n",
        "        for batch_size in batch_size_values:\n",
        "            # Print the current batch size being processed\n",
        "            print(f\"Processing batch size: {batch_size}\")\n",
        "\n",
        "            # Initialize the pipeline outside the loop to avoid repeated initialization\n",
        "            pipe = pipeline(\n",
        "                \"automatic-speech-recognition\",\n",
        "                model=model.half(),\n",
        "                device=device,\n",
        "                chunk_length_s=30,\n",
        "                tokenizer=processor.tokenizer,\n",
        "                feature_extractor=processor.feature_extractor,\n",
        "                torch_dtype=torch_dtype\n",
        "            )\n",
        "\n",
        "            # Run inference in batches\n",
        "            for i in range(0, len(audio_files), batch_size):\n",
        "                batch_files = audio_files[i:i + batch_size]\n",
        "                print(\"Batch Files: \", batch_files)\n",
        "\n",
        "                inference_start_time = time()\n",
        "                results = pipe(batch_files)\n",
        "                inference_end_time = time()\n",
        "\n",
        "                total_inference_time = inference_end_time - inference_start_time\n",
        "                avg_inference_time_per_file = total_inference_time / len(batch_files) if batch_files else 0\n",
        "\n",
        "                # Record the experiment logs in the CSV file\n",
        "                csv_writer.writerow([torch_dtype, batch_size, avg_inference_time_per_file])\n",
        "\n",
        "                print('Total Inference Time for the batch: ', total_inference_time)\n",
        "                print(\"===================================\")\n",
        "            print(\"\\n\")\n",
        "\n",
        "print(f\"Logs saved to {csv_file_name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the change of batch size"
      ],
      "metadata": {
        "id": "lNCouX65QJRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
        "from time import time\n",
        "import csv\n",
        "from pydub import AudioSegment\n",
        "\n",
        "\n",
        "# Define the device and supported torch data types\n",
        "device = \"cpu\"\n",
        "\n",
        "# Function to get audio duration in minutes\n",
        "def audio_duration_in_minutes(file_path):\n",
        "    audio = AudioSegment.from_file(file_path)\n",
        "    return len(audio) / 60000.0\n",
        "\n",
        "# Specify the local path to the pre-trained model directory\n",
        "model_id = \"openai/whisper-small\"\n",
        "\n",
        "# Load the pre-trained model from the local directory\n",
        "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
        "    model_id, torch_dtype=torch.float32\n",
        ")\n",
        "\n",
        "# Move the model to the selected device\n",
        "model.to(device)\n",
        "\n",
        "# Load the processor from the specific snapshot directory within the model directory\n",
        "processor = AutoProcessor.from_pretrained(\n",
        "   \"openai/whisper-small\")\n",
        "\n",
        "# Parameters\n",
        "dtype_precision_values = [torch.float32]\n",
        "batch_size_values = [1, 8, 9]\n",
        "\n",
        "# INPUT FILES\n",
        "audio_files = [\n",
        "    \"testing (1).mp3\",\n",
        "    \"testing (2).mp3\",\n",
        "    \"testing (3).mp3\",\n",
        "    \"testing (4).mp3\",\n",
        "    \"testing (5).mp3\",\n",
        "    \"testing (6).mp3\",\n",
        "    \"testing (7).mp3\",\n",
        "    \"testing (8).mp3\",\n",
        "    \"testing (9).mp3\",\n",
        "]\n",
        "\n",
        "# Initialize a CSV file for recording experiment logs\n",
        "csv_file_name = \"try_SmallBatch_16.csv\"\n",
        "with open(csv_file_name, 'w', newline='') as csv_file:\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerow(['Dtype Precision', 'Batch Size', 'Inference Time', 'File(s) Processed'])\n",
        "\n",
        "    for dtype_precision in dtype_precision_values:\n",
        "        torch_dtype = dtype_precision\n",
        "        print(\"===================================\")\n",
        "        for batch_size in batch_size_values:\n",
        "            # Print the current batch size being processed\n",
        "            print(f\"Processing batch size: {batch_size}\")\n",
        "\n",
        "            # Run inference in batches\n",
        "            for i in range(0, len(audio_files), batch_size):\n",
        "\n",
        "                # Initialize the pipeline outside the loop to avoid repeated initialization\n",
        "                pipe = pipeline(\n",
        "                    \"automatic-speech-recognition\",\n",
        "                    model=model,\n",
        "                    device=device,\n",
        "                    chunk_length_s=30,\n",
        "                    tokenizer=processor.tokenizer,\n",
        "                    feature_extractor=processor.feature_extractor,\n",
        "                    torch_dtype=torch_dtype,\n",
        "                    batch_size = batch_size\n",
        "                )\n",
        "\n",
        "                batch_files = audio_files[i:i + batch_size]\n",
        "                filenames = list(batch_files)  # Capture filenames\n",
        "\n",
        "                inference_start_time = time()\n",
        "                results = pipe(batch_files)\n",
        "                inference_end_time = time()\n",
        "\n",
        "                total_inference_time = inference_end_time - inference_start_time\n",
        "                avg_inference_time_per_file = total_inference_time / len(batch_files) if batch_files else 0\n",
        "\n",
        "                # Append audio duration for single-file batches\n",
        "                if len(filenames) == 1:\n",
        "                    filenames[0] += f\" ({audio_duration_in_minutes(filenames[0]):.2f} mins)\"\n",
        "\n",
        "                # Record the experiment logs in the CSV file\n",
        "                csv_writer.writerow([torch_dtype, batch_size, avg_inference_time_per_file, \", \".join(filenames)])\n",
        "\n",
        "                print(\"Result : \", results)\n",
        "                print(f\"Total Inference Time for the batch: {total_inference_time}\")\n",
        "                print(\"===================================\")\n",
        "            print(\"\\n\")\n",
        "\n",
        "    print(f\"Logs saved to {csv_file_name}\")\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Document :\n",
        "\n",
        "(1) It is fast then others but accuracy low.\n",
        "(2) Distil-Whisper is currently only available for English speech recognition.\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 889
        },
        "id": "Vq-BLMzcQRs7",
        "outputId": "e3ae478d-2ee8-43ca-954d-8266e6453ebf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===================================\n",
            "Processing batch size: 1\n",
            "Result :  [{'text': ' Today we will tell you story. The topic is the crow and the fox. One day the crow was eating a piece of cheese. A cunning fox came there. He thought of asking the crow to sing a song. The foolish crow opened its mouth to sing. The cheese fell down. The cunning fox took the cheese and ran away. Moron, think before you act. Story from Panjatandra Tales. Thank you.'}]\n",
            "Total Inference Time for the batch: 29.467626571655273\n",
            "===================================\n",
            "Result :  [{'text': ' Artificial Intelligence has stood up to the front line of a real-world problem solving and business transformation. While intelligent document processing become a vital component in the global effort to drive intelligent automation into cooperative worldwide. IDP solution reads the unstructured raw data in complicated document using various AI related technologies. Including RPA boards, Optical Character Recognition, Natural Language Processing, Computer Vision and Machine Learning. IDP then gathers the crucial data and transform into the structure, patent and usable formats for is on shell process. Including Government, insurance, order invoicing and loan processing forms. Finally, IDP gathered the required data and forwarded it to appropriate departments or places first year along the line into the process.'}]\n",
            "Total Inference Time for the batch: 37.874573945999146\n",
            "===================================\n",
            "Result :  [{'text': ' Hello, I am Aghai and I am a software engineer intern. My current focus is on optimizing customer service. Of course, what do you share will depend on the situation and on the audience. If you are not sure what to share, your name and job title is a great place to start. If there is an option to elaborate, you can also share other details such as current projects, your expertise on your graphical location. The second part of the introduction is past tense. This is where all you can add or three points that will provide with relevant details about your background. It is also your option to establish a gravity bill. Consider your education and other credentials, past projects, employers and accomplishments. My background is in computer science. Before joining this team, I worked with Bigdata to identify insights for our client in the health care industry.'}]\n",
            "Total Inference Time for the batch: 39.060035943984985\n",
            "===================================\n",
            "Result :  [{'text': \" A one-minute story. Once there was a small village where the people were very poor. One day a king came to the village and offered to give each person a gold coin. Everyone was overjoyed and grateful except for one old woman who refused to take the coin. When asked why, she replied, I don't need a gold coin. I have something much more valuable. A Peaceful Heart Moral of the story is, a peaceful heart is more valuable than gold. Thanks for watching. Like, share, subscribe.\"}]\n",
            "Total Inference Time for the batch: 34.24505591392517\n",
            "===================================\n",
            "Result :  [{'text': \" The two silly goats, short moral story. Once upon a time, there were two silly goats. They wanted to cross a narrow bridge. One silly goat was on one side, the other silly goat was on the other side. They couldn't pass each other. Now both of them wanted to be first to cross. They began to fight. As they were fighting, both fell into the water and drowned. Moral of the story. Foolishness is always punished.\"}]\n",
            "Total Inference Time for the batch: 38.65545058250427\n",
            "===================================\n",
            "Result :  [{'text': \" A very short story with a very short moral. Once there was a girl with bright blue eyes who did only things that made her happy. The only time she wasn't happy was when she forgot that she only did things that made her happy. The end.\"}]\n",
            "Total Inference Time for the batch: 20.378854036331177\n",
            "===================================\n",
            "Result :  [{'text': ' My name is Abhay Mishra. I am currently pursuing computer science engineering from Jameli Devi Group of Institution. Also I am working as an intern in a soft-dude company under Mradul Kanuvo sir. Currently I am working in a project related to the speech to text. Currently I am using the whisper to convert the speech to text.'}]\n",
            "Total Inference Time for the batch: 20.90428900718689\n",
            "===================================\n",
            "Result :  [{'text': \" A very short moral story. with disappointment. Then the girl handed one to her mother and said, Here, this is the sweeter one. Moral, don't judge too early.\"}]\n",
            "Total Inference Time for the batch: 17.730902671813965\n",
            "===================================\n",
            "Result :  [{'text': ' Hello everyone, I am ready with one more short story for you all. Squirrel was very supportive and always won the race. The puppy used to feel bad and thought that of no use. One day it was raining heavily and the squirrel fell in a problem. He started jumping on the water puddle and suddenly fell down. He called his friendppy for help. The puppy came running to help his friend. The squirrel climbed on its back and reached the safe place. He thanked his friend for saving his life. Everyone is unique in their own way, just have confidence in you. Thank you.'}]\n",
            "Total Inference Time for the batch: 42.048099756240845\n",
            "===================================\n",
            "\n",
            "\n",
            "Processing batch size: 8\n",
            "Result :  [{'text': ' Today we will tell you story. The topic is the crow and the fox. One day the crow was eating a piece of cheese. A cunning fox came there. He thought of asking the crow to sing a song. The foolish crow opened its mouth to sing. The cheese fell down. The cunning fox took the cheese and ran away. Moron, think before you act. Story from Panjatandra Tales. Thank you.'}, {'text': ' Artificial Intelligence has stood up to the front line of a real-world problem solving and business transformation. While intelligent document processing become a vital component in the global effort to drive intelligent automation into cooperative worldwide. IDP solution reads the unstructured raw data in complicated document using various AI related technologies. Including RPA boards, Optical Character Recognition, Natural Language Processing, Computer Vision and Machine Learning. IDP then gathers the crucial data and transform into the structure, patent and usable formats for is on shell process. Including Government, insurance, order invoicing and loan processing forms. Finally, IDP gathered the required data and forwarded it to appropriate departments or places first year along the line into the process.'}, {'text': ' Hello, I am Aghai and I am a software engineer intern. My current focus is on optimizing customer service. Of course, what do you share will depend on the situation and on the audience. If you are not sure what to share, your name and job title is a great place to start. If there is an option to elaborate, you can also share other details such as current projects, your expertise on your graphical location. The second part of the introduction is past tense. This is where all you can add or three points that will provide with relevant details about your background. It is also your option to establish a gravity bill. Consider your education and other credentials, past projects, employers and accomplishments. My background is in computer science. Before joining this team, I worked with Bigdata to identify insights for our client in the health care industry.'}, {'text': \" A one-minute story. Once there was a small village where the people were very poor. One day a king came to the village and offered to give each person a gold coin. Everyone was overjoyed and grateful except for one old woman who refused to take the coin. When asked why, she replied, I don't need a gold coin. I have something much more valuable. A Peaceful Heart Moral of the story is, a peaceful heart is more valuable than gold. Thanks for watching. Like, share, subscribe.\"}, {'text': \" The two silly goats, short moral story. Once upon a time, there were two silly goats. They wanted to cross a narrow bridge. One silly goat was on one side, the other silly goat was on the other side. They couldn't pass each other. Now both of them wanted to be first to cross. They began to fight. As they were fighting, both fell into the water and drowned. Moral of the story. Foolishness is always punished.\"}, {'text': \" A very short story with a very short moral. Once there was a girl with bright blue eyes who did only things that made her happy. The only time she wasn't happy was when she forgot that she only did things that made her happy. The end.\"}, {'text': ' My name is Abhay Mishra. I am currently pursuing computer science engineering from Jameli Devi Group of Institution. Also I am working as an intern in a soft-dude company under Mradul Kanuvo sir. Currently I am working in a project related to the speech to text. Currently I am using the whisper to convert the speech to text.'}, {'text': \" A very short moral story. with disappointment. Then the girl handed one to her mother and said, Here, this is the sweeter one. Moral, don't judge too early.\"}]\n",
            "Total Inference Time for the batch: 229.9903793334961\n",
            "===================================\n",
            "Result :  [{'text': ' Hello everyone, I am ready with one more short story for you all. Squirrel was very supportive and always won the race. The puppy used to feel bad and thought that of no use. One day it was raining heavily and the squirrel fell in a problem. He started jumping on the water puddle and suddenly fell down. He called his friendppy for help. The puppy came running to help his friend. The squirrel climbed on its back and reached the safe place. He thanked his friend for saving his life. Everyone is unique in their own way, just have confidence in you. Thank you.'}]\n",
            "Total Inference Time for the batch: 43.681318044662476\n",
            "===================================\n",
            "\n",
            "\n",
            "Processing batch size: 9\n",
            "Result :  [{'text': ' Today we will tell you story. The topic is the crow and the fox. One day the crow was eating a piece of cheese. A cunning fox came there. He thought of asking the crow to sing a song. The foolish crow opened its mouth to sing. The cheese fell down. The cunning fox took the cheese and ran away. Moron, think before you act. Story from Panjatandra Tales. Thank you.'}, {'text': ' Artificial Intelligence has stood up to the front line of a real-world problem solving and business transformation. While intelligent document processing become a vital component in the global effort to drive intelligent automation into cooperative worldwide. IDP solution reads the unstructured raw data in complicated document using various AI related technologies. Including RPA boards, Optical Character Recognition, Natural Language Processing, Computer Vision and Machine Learning. IDP then gathers the crucial data and transform into the structure, patent and usable formats for is on shell process. Including Government, insurance, order invoicing and loan processing forms. Finally, IDP gathered the required data and forwarded it to appropriate departments or places first year along the line into the process.'}, {'text': ' Hello, I am Aghai and I am a software engineer intern. My current focus is on optimizing customer service. Of course, what do you share will depend on the situation and on the audience. If you are not sure what to share, your name and job title is a great place to start. If there is an option to elaborate, you can also share other details such as current projects, your expertise on your graphical location. The second part of the introduction is past tense. This is where all you can add or three points that will provide with relevant details about your background. It is also your option to establish a gravity bill. Consider your education and other credentials, past projects, employers and accomplishments. My background is in computer science. Before joining this team, I worked with Bigdata to identify insights for our client in the health care industry.'}, {'text': \" A one-minute story. Once there was a small village where the people were very poor. One day a king came to the village and offered to give each person a gold coin. Everyone was overjoyed and grateful except for one old woman who refused to take the coin. When asked why, she replied, I don't need a gold coin. I have something much more valuable. A Peaceful Heart Moral of the story is, a peaceful heart is more valuable than gold. Thanks for watching. Like, share, subscribe.\"}, {'text': \" The two silly goats, short moral story. Once upon a time, there were two silly goats. They wanted to cross a narrow bridge. One silly goat was on one side, the other silly goat was on the other side. They couldn't pass each other. Now both of them wanted to be first to cross. They began to fight. As they were fighting, both fell into the water and drowned. Moral of the story. Foolishness is always punished.\"}, {'text': \" A very short story with a very short moral. Once there was a girl with bright blue eyes who did only things that made her happy. The only time she wasn't happy was when she forgot that she only did things that made her happy. The end.\"}, {'text': ' My name is Abhay Mishra. I am currently pursuing computer science engineering from Jameli Devi Group of Institution. Also I am working as an intern in a soft-dude company under Mradul Kanuvo sir. Currently I am working in a project related to the speech to text. Currently I am using the whisper to convert the speech to text.'}, {'text': \" A very short moral story. with disappointment. Then the girl handed one to her mother and said, Here, this is the sweeter one. Moral, don't judge too early.\"}, {'text': ' Hello everyone, I am ready with one more short story for you all. Squirrel was very supportive and always won the race. The puppy used to feel bad and thought that of no use. One day it was raining heavily and the squirrel fell in a problem. He started jumping on the water puddle and suddenly fell down. He called his friendppy for help. The puppy came running to help his friend. The squirrel climbed on its back and reached the safe place. He thanked his friend for saving his life. Everyone is unique in their own way, just have confidence in you. Thank you.'}]\n",
            "Total Inference Time for the batch: 275.5595791339874\n",
            "===================================\n",
            "\n",
            "\n",
            "Logs saved to try_SmallBatch_16.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nDocument :\\n\\n(1) It is fast then others but accuracy low.\\n(2) Distil-Whisper is currently only available for English speech recognition.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMP4Wzt+cmPsG2a+RVciPd0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}